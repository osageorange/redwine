---
title: "Classification Analysis of Red Wine Quality"
author: Tyler Schappe
output:
  word_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(MASS); library(ggplot2); library(psych); library(tidyverse); library(rpart)
library(rpart.plot); library(factoextra); library(nnet); library(caret); library(leaps)
library(glmnet); library(pls); library(e1071); library(ranger); library(randomForest)
library(car); library(ggcorrplot)
set.seed(1)
red.wine <- read.csv('/Users/tschappe/Documents/NC\ State\ Classes/ST563/Final\ Project/winequality-red.csv', sep = ';')
rows = nrow(red.wine); vars = ncol(red.wine)
train.test.split = 0.8
#str(red.wine)
#summary(red.wine)
#colSums(is.na(red.wine))
```

```{r }
# Citation - Custom function from rstudio reference for plot visualization. 
# All credits to Jie Huang.
# customized function to evaluate model performance for continuous predictors
eval = function(pred, true, plot = F, title = "") {
  rmse = sqrt(mean((pred - true)^2))
  mae = mean(abs(pred - true))
  cor = cor(pred, true)
  if (plot == TRUE) {
    par(mfrow = c(1,2), oma = c(0, 0, 2, 0))
    diff = pred - true
    plot(jitter(true, factor = 1), 
         jitter(pred, factor = 0.5),
         pch = 3, asp = 1,
         xlab = "Truth", ylab = "Predicted") 
    abline(0,1, lty = 2)
    hist(diff, breaks = 20, main = NULL)
    mtext(paste0(title, " predicted vs. true using test set"), outer = TRUE, line = -3)
    par(mfrow = c(1,1))}
  return(list(rmse = rmse,
              mae = mae,
              cor = cor))
}
```

# 1. EDA, Data Quality, Normality Exploration

## 1.1 Check for missing data and quantile ranges for predictors

### [Summary](#rwds)

### Red Wine dataset was verified for no missing data values. From summary, we see that there seems to be varied ranges within the variables hence it will be advisable to standardize them.

## 1.2 Analyze "quality" response levels proportions.

### [Red Wine quality proportions](#rwqp)

### We see that there are six "quality" levels and the number of observation in 3,4 and 8 quality levels are not in proportion to quality 5,6 and 7. Careful choice of train and test dataset is necessary to avoid overfitting or underfitting. Hence we must take care while sampling to ensure we obtain proportionate representations from all quality level for predictions. We will approach sampling the training and test set for further model fit by applying sampling within each quality level so that we get enough representative from all 6 red wine  quality levels.

```{r }
red.wine.3 <- red.wine[which(red.wine$quality == 3), ] ; idx.3 = sample(1:nrow(red.wine.3), train.test.split * nrow(red.wine.3))
red.wine.4 <- red.wine[which(red.wine$quality == 4), ] ; idx.4 = sample(1:nrow(red.wine.4), train.test.split * nrow(red.wine.4))
red.wine.5 <- red.wine[which(red.wine$quality == 5), ] ; idx.5 = sample(1:nrow(red.wine.5), train.test.split * nrow(red.wine.5))
red.wine.6 <- red.wine[which(red.wine$quality == 6), ] ; idx.6 = sample(1:nrow(red.wine.6), train.test.split * nrow(red.wine.6))
red.wine.7 <- red.wine[which(red.wine$quality == 7), ] ; idx.7 = sample(1:nrow(red.wine.7), train.test.split * nrow(red.wine.7))
red.wine.8 <- red.wine[which(red.wine$quality == 8), ] ; idx.8 = sample(1:nrow(red.wine.8), train.test.split * nrow(red.wine.8))
red.wine.3.train = red.wine.3[idx.3,]; red.wine.3.test = red.wine.3[-idx.3,];
red.wine.4.train = red.wine.4[idx.4,]; red.wine.4.test = red.wine.4[-idx.4,];
red.wine.5.train = red.wine.5[idx.5,]; red.wine.5.test = red.wine.5[-idx.5,];
red.wine.6.train = red.wine.6[idx.6,]; red.wine.6.test = red.wine.6[-idx.6,];
red.wine.7.train = red.wine.7[idx.7,]; red.wine.7.test = red.wine.7[-idx.7,];
red.wine.8.train = red.wine.8[idx.8,]; red.wine.8.test = red.wine.8[-idx.8,];

# Train and Test dataset
train <- rbind(red.wine.3.train,red.wine.4.train,red.wine.5.train,red.wine.6.train,red.wine.7.train,red.wine.8.train)
test <- rbind(red.wine.3.test,red.wine.4.test,red.wine.5.test,red.wine.6.test,red.wine.7.test,red.wine.8.test) 
x.train = model.matrix(quality~., train)[,-1]
y.train = train$quality
x.test  = model.matrix(quality~., test)[,-1]
y.test  = test$quality

```

# 6. Classification

```{r }
# collapse the ratings into a smaller number of levels
red.wine.class <- red.wine
rating <- c("low","med", "high")

for(i in 1:nrow(red.wine)){
    if(red.wine.class$quality[i] <= 5){
        red.wine.class$quality.rating[i]= rating[1]
     } else if(red.wine.class$quality[i] == 6){
        red.wine.class$quality.rating[i] = rating[2]
     } else if(red.wine.class$quality[i] > 6){
        red.wine.class$quality.rating[i] = rating[3]
     }
}
red.wine.class <- within(red.wine.class, rm(quality))
```

## 6.1 Multinomial Logistic Regression

```{r }
## extracting coefficients from the model and exponentiate
#exp(coef(multinom.fit))
#head(probability.table <- fitted(multinom.fit))
```

```{r include=FALSE}
# Fit 1 - All, Fit 2 - Quadratic, Fit3 - regression.tree, Fit4 - lasso, Fit5 - PCA

idx = sample(rows, train.test.split * rows)
train.class = red.wine.class[idx,]
test.class = red.wine.class[-idx,]
```

## 6.2 Naive Bayes Classifier

```{r}
train.class = red.wine.class[idx,]
test.class = red.wine.class[-idx,]
bayes.fit1 <- naiveBayes(quality.rating ~ ., data = train.class)
bayes.fit1.pred <- as.data.frame(predict(bayes.fit1, type = "raw", newdata = test.class))
bayes.fit1.pred$pred.class <- apply(bayes.fit1.pred, MARGIN = 1, FUN = function(x) names(x[x == max(x)]))

#Make a confusion matrix
(bayes.cm <- with(data.frame(quality.rating = test.class$quality.rating, bayes.pred.qual = bayes.fit1.pred$pred.class), table(quality.rating, bayes.pred.qual)))
print(paste0("This naive Bayes classifier achieves a test missclassification error rate of ", 1 - sum(diag(bayes.cm))/sum(bayes.cm)))

#Calculate variable importance
bayes.err <- 1:(ncol(train.class)-1)
for (i in 1:(ncol(train.class)-1)) {
  train <- train.class[,-i]
  bayes.qual <- naiveBayes(quality.rating ~ ., data=train)
  bayes.qual.pred <- as.data.frame(predict(bayes.qual, type="raw", test.class[,-i]))
  bayes.qual.pred.class <- apply(bayes.qual.pred, MARGIN = 1, FUN = function(x) names(x[x == max(x)]))
  bayes.qual.cm <- table(bayes.qual.pred.class, test.class$quality.rating)
  bayes.err[i] <- 1 - sum(diag(bayes.qual.cm))/sum(bayes.qual.cm)
}
#Find the variables for which the error increases the most when dropped
data.frame(variable=colnames(train.class[,order(bayes.err,decreasing = T)[1:3]]), error.increase=bayes.err[order(bayes.err,decreasing = T)][1:3] - (1 - sum(diag(bayes.cm))/sum(bayes.cm)))
```


### 6.3 Linear Discriminant Analysis

```{r}
library(MASS)
lda.qual <- lda(quality.rating ~ ., data=train.class)

#Make predictions based on test data set
lda.qual.pred <- predict(lda.qual, test.class)
#Make a confusion matrix based on test data
(lda.qual.cm <- table(lda.qual.pred$class, test.class$quality.rating))

#Calculate the overall error rate
print(paste0("The test error rate for this LDA was ",1 - sum(diag(lda.qual.cm))/sum(lda.qual.cm)))

#Calculate variable importance
lda.err <- 1:(ncol(train.class)-1)
for (i in 1:(ncol(train.class)-1)) {
  train <- train.class[,-i]
  lda.qual <- lda(quality.rating ~ ., data=train)
  lda.qual.pred <- predict(lda.qual, test.class[,-i])
  lda.qual.cm <- table(lda.qual.pred$class, test.class$quality.rating)
  lda.err[i] <- 1 - sum(diag(lda.qual.cm))/sum(lda.qual.cm)
}
#Find the variables for which the error increases the most when dropped
data.frame(variable=colnames(train.class[,order(lda.err,decreasing = T)[1:3]]), error.increase=lda.err[order(lda.err,decreasing = T)][1:3] - (1 - sum(diag(lda.qual.cm))/sum(lda.qual.cm)))
```

### 6.4 Quadratic Discriminant Analysis

```{r}
library(MASS)
qda.qual <- qda(quality.rating ~ ., data=train.class)

#Make predictions based on test data set
qda.qual.pred <- predict(qda.qual, test.class)
#Make a confusion matrix based on test data
(qda.qual.cm <- table(qda.qual.pred$class, test.class$quality.rating))

#Calculate the overall error rate
print(paste0("The test error rate for this QDA was ", 1 - sum(diag(qda.qual.cm))/sum(qda.qual.cm)))

#Calculate variable importance
qda.err <- 1:(ncol(train.class)-1)
for (i in 1:(ncol(train.class)-1)) {
  train <- train.class[,-i]
  qda.qual <- qda(quality.rating ~ ., data=train)
  qda.qual.pred <- predict(qda.qual, test.class[,-i])
  qda.qual.cm <- table(qda.qual.pred$class, test.class$quality.rating)
  qda.err[i] <- 1 - sum(diag(qda.qual.cm))/sum(qda.qual.cm)
}
#Find the variables for which the error increases the most when dropped
data.frame(variable=colnames(train.class[,order(qda.err,decreasing = T)[1:3]]), error.increase=qda.err[order(qda.err,decreasing = T)][1:3] - (1 - sum(diag(qda.qual.cm))/sum(qda.qual.cm)))


```

### 6.5 Support Vector Machines

```{r}
library(e1071)
# #First tuning run
# svm.tune <- tune(svm, as.factor(quality.rating) ~ ., data=train.class, kernel="radial",
#                  ranges = list(
#                    cost = c(0.1, 1, 10, 100, 1000),
#                    gamma = seq.default(from=1, to=4, by=1)))
# summary(svm.tune)
# 
# #Second tuning run
# svm.tune2 <- tune(svm, as.factor(quality.rating) ~ ., data=train.class, kernel="radial",
#                  ranges = list(
#                    cost = seq.default(from=0.2, to=2, by=0.2),
#                    gamma = seq.default(from=0.2, to=2, by=0.2)))
# summary(svm.tune2)
# #Cost 1.8, gamma 0.6 is the best

#Final model with tuned parameters
svm.best <- svm(as.factor(quality.rating) ~ ., data=red.wine.class, kernel="radial", cost=1.8, gamma=0.6, decision.values=T)

#Make confusion matrix
(svm.cm <- with(data.frame(quality.rating = as.factor(test.class$quality.rating), pred.quality = predict(svm.best, newdata = test.class)), table(quality.rating, pred.quality)))
#Calculate test error rate
print(paste0("This support vector machine with radial kernel had a test error rate of ", 1 - sum(diag(svm.cm))/sum(svm.cm)))

#Make a slice plot of just two variables
plot(svm.best, data=red.wine.class, fixed.acidity ~ total.sulfur.dioxide, slice = list(
                                                                      chlorides = mean(red.wine.class$chlorides), 
                                                                      volatile.acidity = mean(red.wine.class$volatile.acidity),
                                                                      citric.acid = mean(red.wine.class$citric.acid),
                                                                      residual.sugar = mean(red.wine.class$residual.sugar),
                                                                      free.sulfur.dioxide = mean(red.wine.class$free.sulfur.dioxide),
                                                                      sulphates = mean(red.wine.class$sulphates),
                                                                      density = mean(red.wine.class$density),
                                                                      alcohol = mean(red.wine.class$alcohol),
                                                                      pH = mean(red.wine.class$pH)
                                                                      ))
#Make ROC plot
# library(ROCR)
# rocplot=function(pred, truth, ...){
# predob = prediction(pred, truth)
# perf = performance(predob, "tpr", "fpr")
# plot(perf,...)}
# 
# predicted <- predict(svm.best, data=train.class, decision.values=T)
# svm.best.fitted <- as.data.frame(predict(svm.best, data=train.class, decision.values=T))
# par(mfrow=c(1,2))
# rocplot(svm.best.fitted, train.class$quality, main="Training Data")
#NOTE: Can't make ROC plot in cases with > 2 classes!!

#Calculate variable importance
svm.err <- 1:(ncol(train.class)-1)
for (i in 1:(ncol(train.class)-1)) {
  train <- train.class[,-i]
  svm.qual <- svm(as.factor(quality.rating) ~ ., data=train, kernel="radial", cost=1.8, gamma=0.6, decision.values=T)
  svm.qual.pred <- predict(svm.qual, test.class[,-i])
  svm.qual.cm <- table(svm.qual.pred, test.class$quality.rating)
  svm.err[i] <- 1 - sum(diag(svm.qual.cm))/sum(svm.qual.cm)
}
#Find the variables for which the error increases the most when dropped
data.frame(variable=colnames(train.class[,order(svm.err,decreasing = T)[1:3]]), error.increase=svm.err[order(svm.err,decreasing = T)][1:3] - (1 - sum(diag(svm.cm))/sum(svm.cm)))

```

This support vector machine method was able to achieve an overall test misclassification error rate of about 0.27.


## 6.6 Random Forests
```{r}
library(randomForest)
t <- 11
forests.qual <- lapply(1:t, FUN = function(f) randomForest(as.factor(quality.rating) ~ ., 
                                                               data=train.class, mtry=f, importance=T))


forests.qual.pred <- lapply(forests.qual, FUN = function(f) predict(f, type="response", newdata=test.class))
forests.qual.cm <- lapply(forests.qual.pred, FUN = function(f) with(data.frame(forest.pred.qual=f, true.qual=test.class$quality.rating), table(forest.pred.qual, true.qual)))
forests.qual.cm[[2]]
forests.qual.err <- sapply(forests.qual.pred, FUN = 
                                function(f) 1 - sum(diag(table(f, test.class$quality.rating)))/sum(table(f, test.class$quality.rating)))

#Plot the # of parameters retained vs. test error
qplot(m, err, data = data.frame(m=1:t, err=forests.qual.err))+
  theme_bw()+
  geom_line()
#Find the smallest error
forests.qual.err[forests.qual.err == min(forests.qual.err)]
order(forests.qual.err)
print(paste0("Considering ", order(forests.qual.err)[1], " variables at each branch is the best"))

#Make a final model with the full dataset using the tuned parameter
forests.qual.best <- randomForest(as.factor(quality.rating) ~ ., red.wine.class, mtry=forests.qual[[order(forests.qual.err)[1]]]$mtry)

#Find the most important variables from the best model
forests.qual.best.imp <- importance(forests.qual.best)
forests.qual.best.imp[order(forests.qual.best.imp, decreasing = T),]

```

Based on this random forest analysis in which the number of variables kept at each split was tuned, alcohol, sulphates, and volatile acidity are the top three most important variables.


## 6.7 Boosting
```{r}
library(gbm)
#Since multinomial response is not supported by gbm(), split the data into two classes instead
red.wine.bin.class <- red.wine
red.wine.bin.class$quality.rating[red.wine.bin.class$quality <= 6] <- 0
red.wine.bin.class$quality.rating[red.wine.bin.class$quality > 6] <- 1
red.wine.bin.class <- subset(red.wine.bin.class, select = -c(quality))
#Split data
train.bin.class = red.wine.bin.class[idx,]
test.bin.class = red.wine.bin.class[-idx,]


# boost.qual <- lapply(seq.default(from=0.1, to=2, by=0.1), FUN = function(l) gbm(quality.rating ~ ., data=train.bin.class, distribution = "adaboost", n.trees=5000, n.cores = 8, interaction.depth = 6, shrinkage = l))
# # boost.qual.cv.err <- lapply(boost.qual, FUN = function(l) print(gbm.perf(l, method="cv")))
# boost.qual.pred <- lapply(boost.qual, FUN = function(l) predict(l, type="link", n.trees=5000, newdata=test.bin.class))
# boost.qual.pred.class <- lapply(boost.qual.pred, FUN = function(l) ifelse(binomial(link="logit")$linkinv(l) > 0.5, 1, 0))
# boost.qual.cm <- lapply(boost.qual.pred.class, FUN = 
#                                 function(l) table(l, test.bin.class$quality.rating))
# boost.qual.cm
# boost.qual.err <- sapply(boost.qual.pred.class, FUN = 
#                                 function(l) 1 - sum(diag(table(l, test.bin.class$quality.rating)))/sum(table(l, test.bin.class$quality.rating)))
# 
# #Plot the # of parameters retained vs. test error
# qplot(m, err, data = data.frame(m=seq.default(from=0, to=0.5, by=0.01), err=boost.qual.err))+
#   theme_bw()+
#   geom_line()
# #Find the smallest error
# boost.qual.err[boost.qual.err == min(boost.qual.err)]
# print(paste0("A shrinkage value of ", seq.default(from=0, to=0.5, by=0.01)[order(boost.qual.err)[1]], " gives the lowest test error."))
#A shrinkage value of 1.6 gives the lowest error.

#Make final model for test MSE
boost.qual.best.train <- gbm(quality.rating ~ ., data=train.bin.class, distribution = "adaboost", n.trees=5000, n.cores = 8, interaction.depth = 6, shrinkage = 1.6)
boost.qual.best.train.pred <- ifelse(binomial(link="logit")$linkinv(predict(boost.qual.best.train, type="link", n.trees=800, newdata=test.bin.class)) > 0.5, 1, 0)
with(data.frame(boost.pred.quality = boost.qual.best.train.pred, quality.rating = test.bin.class$quality.rating), table(boost.pred.quality, quality.rating))
#Calculate error rate
print(paste0("This boosting model had a test error rate of ", 1 - sum(diag(table(boost.qual.best.train.pred, test.bin.class$quality.rating)))/sum(table(boost.qual.best.train.pred, test.bin.class$quality.rating))))

#Make final model
boost.qual.best <- gbm(quality.rating ~ ., data=red.wine.bin.class, distribution = "adaboost", n.trees=5000, n.cores = 8, interaction.depth = 6, shrinkage = 1.6)
#Create confusion matrix
boost.qual.best.pred <- ifelse(binomial(link="logit")$linkinv(predict(boost.qual.best, type="link", n.trees=800, newdata=test.bin.class)) > 0.5, 1, 0)
with(data.frame(boost.pred.quality = boost.qual.best.pred, quality.rating = test.bin.class$quality.rating), table(boost.pred.quality, quality.rating))
#Calculate error rate
1 - sum(diag(table(boost.qual.best.pred, test.bin.class$quality.rating)))/sum(table(boost.qual.best.pred, test.bin.class$quality.rating))

#Find the most important variables
(boost.qual.imp <- summary(boost.qual.best))
```